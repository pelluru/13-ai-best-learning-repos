{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e7c6a5a",
   "metadata": {},
   "source": [
    "# Tutorial - chapter 09 - petastorm-pyspark-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12256f40",
   "metadata": {},
   "source": [
    "### 1. load parquet data into pytorch loader\n",
    "\n",
    "file path: `notebooks/images_data/silver/augmented`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1fc3c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/petastorm/spark/spark_dataset_converter.py:28: FutureWarning: pyarrow.LocalFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.LocalFileSystem instead.\n",
      "  from pyarrow import LocalFileSystem\n"
     ]
    }
   ],
   "source": [
    "# spark\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.types import BinaryType,StringType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions \n",
    "from pyspark.sql.types import *\n",
    "\n",
    "#petastorm\n",
    "\n",
    "from petastorm.spark import SparkDatasetConverter, make_spark_converter\n",
    "from petastorm import TransformSpec \n",
    "    \n",
    "    \n",
    "import io\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from functools import partial \n",
    "\n",
    "\n",
    "# train images with pytorch\n",
    "#from torchvision import transforms\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, STATUS_OK\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "\n",
    "\n",
    "# import mlflow\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97770b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark session:\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Distributed Pytorch training\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\",True) \\\n",
    "    .config(\"spark.memory.offHeap.size\",\"30g\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b7a667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from petastorm.spark import SparkDatasetConverter, make_spark_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a16abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(SparkDatasetConverter.PARENT_CACHE_DIR_URL_CONF, 'petastorm_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dcacae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"images_data/silver/augmented\"\n",
    "mlflow_model_dir_path = \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35adda1",
   "metadata": {},
   "source": [
    "# Enable MLFlow tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47880879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "try:\n",
    "    from torchmetrics.functional import accuracy\n",
    "except ImportError:\n",
    "    from pytorch_lightning.metrics.functional import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4088b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/06/20 01:56:23 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of pytorch. If you encounter errors during autologging, try upgrading / downgrading pytorch to a supported version, or try upgrading MLflow.\n",
      "2022/06/20 01:56:23 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/conda/lib/python3.9/site-packages/pytorch_lightning/core/memory.py:16: LightningDeprecationWarning: `pytorch_lightning.core.memory.get_memory_profile` and `pytorch_lightning.core.memory.get_gpu_memory_map` have been moved to `pytorch_lightning.utilities.memory` since v1.5 and will be removed in v1.7.\"\n",
      "2022/06/20 01:56:23 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/conda/lib/python3.9/site-packages/pytorch_lightning/core/memory.py:25: LightningDeprecationWarning: `pytorch_lightning.core.memory.LayerSummary` and `pytorch_lightning.core.memory.ModelSummary` have been moved to `pytorch_lightning.utilities.model_summary` since v1.5 and will be removed in v1.7.\"\n"
     ]
    }
   ],
   "source": [
    "#Enable MLFlow tracking\n",
    "mlflow.set_experiment(mlflow_model_dir_path)\n",
    "# requires pytorch_lightning\n",
    "mlflow.pytorch.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ad2fab",
   "metadata": {},
   "source": [
    "## params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efa07f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (224, 224, 3)\n",
    "BATCH_SIZE = 1\n",
    "#The number of **epochs** is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset. One epoch means that each sample in the training dataset has had an opportunity to update the internal model parameters.\n",
    "SAMPLE_SIZE = 5\n",
    "NUM_EPOCHS = 1\n",
    "NUM_EXECUTERS = 1\n",
    "LEARNING_RATE=0.1\n",
    "RANDOM_SEED_DEFAULT=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ccbca2",
   "metadata": {},
   "source": [
    "## 2. Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6b06782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training data stored in parquet, limiting the dataset for the example\n",
    "df_parquet = spark.read.parquet(data_path)\n",
    "df = df_parquet.select(col(\"content\"), col(\"label_index\").cast(LongType())).limit(SAMPLE_SIZE)\n",
    "  \n",
    "num_classes = df.select(\"label_index\").distinct().count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b2b101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp since we are running localy on a sample\n",
    "num_classes =4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3121989",
   "metadata": {},
   "source": [
    "## 3. Split to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2360759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train , df_val = df.randomSplit([0.6,0.4], seed=12345)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6116e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the content vector into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b2b0c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- content: binary (nullable = true)\n",
      " |-- label_index: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810ef9d0",
   "metadata": {},
   "source": [
    "## 4. Cache the Spark DataFrame using Petastorm Spark Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "030d22ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/petastorm/fs_utils.py:88: FutureWarning: pyarrow.localfs is deprecated as of 2.0.0, please use pyarrow.fs.LocalFileSystem instead.\n",
      "  self._filesystem = pyarrow.localfs\n"
     ]
    }
   ],
   "source": [
    "tmp_path = \"file:/home/jovyan/petastorm_cache/\"\n",
    "\n",
    "# Set a cache directory on DBFS FUSE for intermediate data\n",
    "spark.conf.set(SparkDatasetConverter.PARENT_CACHE_DIR_URL_CONF,tmp_path)\n",
    "\n",
    "\n",
    "#train\n",
    "converter_train = make_spark_converter(df_train)\n",
    "#test\n",
    "converter_val = make_spark_converter(df_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d0df1a",
   "metadata": {},
   "source": [
    "### Petastorm prepreocess\n",
    "used during materlizing spark dataframe with petastorm and bridging to TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41a8dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision, torch\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "def preprocess(image):\n",
    "  \"\"\"\n",
    "  Preprocess an image file bytes for MobileNetV2 (ImageNet) - using torchvision transform and normalize.\n",
    "  \"\"\"\n",
    "#   transform = transforms.Compose([\n",
    "#         transforms.ToTensor()\n",
    "#     ])\n",
    "    \n",
    "  image = Image.open(io.BytesIO(image)).resize([224, 224])\n",
    "  arr = np.array(image)\n",
    "#   image_array_byte = np.array(image)\n",
    "  # convert byte array to float array for PyTorch backward computation\n",
    "#   image_array_float = [float(a) for a in image_array_byte]\n",
    "  #image_array = keras.preprocessing.image.img_to_array(image)\n",
    "#   pytorch_normalize =  transform(image)\n",
    "\n",
    "  return arr\n",
    "\n",
    "\n",
    "\n",
    "def transform_row(pd_batch):\n",
    "  \"\"\"\n",
    "  The input and output of this function are pandas dataframes.\n",
    "  \"\"\"\n",
    "  pd_batch['content'] = pd_batch['content'].map(lambda x: preprocess(x))\n",
    "    \n",
    "\n",
    "  return pd_batch\n",
    "\n",
    "# The output shape of the `TransformSpec` is not automatically known by petastorm, \n",
    "# so you need to specify the shape for new columns in `edit_fields` and specify the order of \n",
    "# the output columns in `selected_fields`.\n",
    "transform_spec_fn = TransformSpec(\n",
    "  func=transform_row, \n",
    "  selected_fields=['content', 'label_index']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77ea1c3",
   "metadata": {},
   "source": [
    "## 5. Get the model MobileNetV2\n",
    "#### Get the model MobileNetV2 from torch hub\n",
    "and only retraining its final layer to fit your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c16f5f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jovyan/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae758303",
   "metadata": {},
   "source": [
    "## 6. Set PyTorch environment for distributed training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07a181ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as described in the book - always set the seed for the machine in distributed training\n",
    "def set_random_seeds(random_seed=0):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8c37629",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seeds(random_seed=RANDOM_SEED_DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9c6489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "    # initialize the process group\n",
    "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16b1dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "\n",
    "# choose the one relevant to your backend.\n",
    "\n",
    "# torch.distributed.init_process_group(backend=\"nccl\")\n",
    "# torch.distributed.init_process_group(backend=\"gloo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8db801a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if next(model.parameters()).is_cuda:\n",
    "#    device = torch.device(\"cuda:{}\".format(local_rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45782ed",
   "metadata": {},
   "source": [
    "## 7. set the train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41b15688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader, steps=100, lr=0.0005, momentum=0.5):\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    ##  train the model \n",
    "    for data in data_loader:\n",
    "        print(data)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d98235f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader,device):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return accuracy\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c79f1be",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "The client socket has timed out after 1800s while trying to connect to (localhost, 12355).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4360048a8ca9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmachine_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-79b9f66b12e9>\u001b[0m in \u001b[0;36msetup\u001b[0;34m(rank, world_size)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# initialize the process group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_process_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gloo\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36minit_process_group\u001b[0;34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options)\u001b[0m\n\u001b[1;32m    593\u001b[0m                 \u001b[0minit_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             )\n\u001b[0;32m--> 595\u001b[0;31m             \u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrendezvous_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m             \u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/distributed/rendezvous.py\u001b[0m in \u001b[0;36m_env_rendezvous_handler\u001b[0;34m(url, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0mmaster_port\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_env_or_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MASTER_PORT\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_c10d_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_addr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaster_port\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/distributed/rendezvous.py\u001b[0m in \u001b[0;36m_create_c10d_store\u001b[0;34m(hostname, port, rank, world_size, timeout)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mstart_daemon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         return TCPStore(\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0mhostname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_daemon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_tenant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         )\n",
      "\u001b[0;31mTimeoutError\u001b[0m: The client socket has timed out after 1800s while trying to connect to (localhost, 12355)."
     ]
    }
   ],
   "source": [
    "setup(1,1)\n",
    "machine_rank = dist.get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62cc59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077544e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine PyTorch distributed data parallel with Petastorm\n",
    "# this approach is replicating the model over the training machines\n",
    "# where each machine operates on one chunk of the data, as described in Chatper 9.\n",
    "    \n",
    "\n",
    "setup(rank=0, world_size=1)    \n",
    "model = model.to(machine_rank)\n",
    "ddp_model = DDP(model, device_ids=[machine_rank])\n",
    "    \n",
    "def train_and_evaluate(_=None):\n",
    "    with converter_train.make_torch_dataloader(transform_spec=transform_spec_fn ,batch_size=BATCH_SIZE) as loader:\n",
    "            outputs = ddp_model(loader)\n",
    "    \n",
    "    with converter_val.make_torch_dataloader(transform_spec=transform_spec_fn,batch_size=BATCH_SIZE,num_epochs=1) as loader:\n",
    "            accuracy = test(model, loader)\n",
    "            return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeb7a80",
   "metadata": {},
   "outputs": [],
   "source": [
    " accuracy = train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b843f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866174ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "להמשיך מכאן - נראה שצריך לסדר את העניין של המערכת עצמה בשביל שזה יהיה מוכן לטובת הרצה בצורה distributed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
