{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "modern-klein",
   "metadata": {},
   "source": [
    "# Clustering CO2 dataset with GaussianMixture\n",
    "Use Machine Learning Methods to cluster cars and their CO2 emission. \n",
    "Dataset by Kaggle. More information can be found [here](https://www.kaggle.com/debajyotipodder/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "processed-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"Intro\") \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "special-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, DoubleType\n",
    "\n",
    "custom_schema = StructType([\n",
    "    StructField(\"Make\", StringType(), True),\n",
    "    StructField(\"Model\", StringType(), True),\n",
    "    StructField(\"Vehicle Class\", StringType(), True),\n",
    "    StructField(\"Cylinders\", DoubleType(), True),\n",
    "    StructField(\"Transmission\", StringType(), True),\n",
    "    StructField(\"Fuel Type\", StringType(), True),\n",
    "    StructField(\"Fuel Consumption City (L/100 km)\", DoubleType(), True),\n",
    "    StructField(\"Fuel Consumption Hwy (L/100 km)\", DoubleType(), True),\n",
    "    StructField(\"Fuel Consumption Comb (L/100 km)\", DoubleType(), True),\n",
    "    StructField(\"Fuel Consumption Comb (mpg)\", DoubleType(), True),\n",
    "    StructField(\"CO2\", DoubleType(), True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "green-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "co2_data = spark.read.format(\"csv\")\\\n",
    "    .schema(custom_schema) \\\n",
    "    .option(\"header\", True) \\\n",
    "    .load(\"../datasets/CO2_Emissions_Canada.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "raised-equality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Make='ACURA', Model='ILX', Vehicle Class='COMPACT', Cylinders=2.0, Transmission='4', Fuel Type='AS5', Fuel Consumption City (L/100 km)=None, Fuel Consumption Hwy (L/100 km)=9.9, Fuel Consumption Comb (L/100 km)=6.7, Fuel Consumption Comb (mpg)=8.5, CO2=33.0),\n",
       " Row(Make='ACURA', Model='ILX', Vehicle Class='COMPACT', Cylinders=2.4, Transmission='4', Fuel Type='M6', Fuel Consumption City (L/100 km)=None, Fuel Consumption Hwy (L/100 km)=11.2, Fuel Consumption Comb (L/100 km)=7.7, Fuel Consumption Comb (mpg)=9.6, CO2=29.0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co2_data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cultural-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_data = co2_data.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mature-checkout",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- Vehicle Class: string (nullable = true)\n",
      " |-- Cylinders: double (nullable = false)\n",
      " |-- Transmission: string (nullable = true)\n",
      " |-- Fuel Type: string (nullable = true)\n",
      " |-- Fuel Consumption City (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Hwy (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (mpg): double (nullable = false)\n",
      " |-- CO2: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "co2_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "level-mixture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Make='ACURA', Model='ILX', Vehicle Class='COMPACT', Cylinders=2.0, Transmission='4', Fuel Type='AS5', Fuel Consumption City (L/100 km)=0.0, Fuel Consumption Hwy (L/100 km)=9.9, Fuel Consumption Comb (L/100 km)=6.7, Fuel Consumption Comb (mpg)=8.5, CO2=33.0),\n",
       " Row(Make='ACURA', Model='ILX', Vehicle Class='COMPACT', Cylinders=2.4, Transmission='4', Fuel Type='M6', Fuel Consumption City (L/100 km)=0.0, Fuel Consumption Hwy (L/100 km)=11.2, Fuel Consumption Comb (L/100 km)=7.7, Fuel Consumption Comb (mpg)=9.6, CO2=29.0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co2_data.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-sellers",
   "metadata": {},
   "source": [
    "# Build Hasher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-embassy",
   "metadata": {},
   "source": [
    "turn the feature columns into one indexed column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "expanded-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import FeatureHasher\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "cols_only_continues = [\"Fuel Consumption City (L/100 km)\", \"Fuel Consumption Hwy (L/100 km)\",\n",
    "        \"Fuel Consumption Comb (L/100 km)\"]\n",
    "\n",
    "hasher = FeatureHasher(outputCol=\"hashed_features\", inputCols=cols_only_continues)\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-roots",
   "metadata": {},
   "source": [
    "# Build Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "breeding-christmas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnivariateFeatureSelector_e99fccf90cbf"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import UnivariateFeatureSelector\n",
    "\n",
    "selector = UnivariateFeatureSelector(outputCol=\"selectedFeatures\", featuresCol=\"hashed_features\", labelCol=\"CO2\")\n",
    "\n",
    "selector.setFeatureType(\"continuous\")\n",
    "selector.setLabelType(\"continuous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-spain",
   "metadata": {},
   "source": [
    "# Create GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dimensional-wisdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import GaussianMixture\n",
    "\n",
    "gm = GaussianMixture(k=42, tol=0.01, seed=10, featuresCol=\"selectedFeatures\", maxIter=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-depth",
   "metadata": {},
   "source": [
    "# Constructing - The Pipeline API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "blessed-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[hasher,selector, gm])\n",
    "# Fit the pipeline to training data.\n",
    "pipeline_model = pipeline.fit(co2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adult-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_by_pipeline = pipeline_model.transform(co2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "necessary-violation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- Vehicle Class: string (nullable = true)\n",
      " |-- Cylinders: double (nullable = false)\n",
      " |-- Transmission: string (nullable = true)\n",
      " |-- Fuel Type: string (nullable = true)\n",
      " |-- Fuel Consumption City (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Hwy (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (mpg): double (nullable = false)\n",
      " |-- CO2: double (nullable = false)\n",
      " |-- hashed_features: vector (nullable = true)\n",
      " |-- selectedFeatures: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_by_pipeline.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-layout",
   "metadata": {},
   "source": [
    "# Persisting the pipeline to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "desirable-costume",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model_with_pip = \"/tmp/pip_model\"\n",
    "pipeline_model.write().overwrite().save(path_model_with_pip)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-milton",
   "metadata": {},
   "source": [
    "# Using our model in Stream processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "given-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume we have data ingested in stream into our system:\n",
    "data_in_stream = spark \\\n",
    "    .readStream \\\n",
    "    .schema(custom_schema) \\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"header\", True) \\\n",
    "    .load(\"StreamData/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "indian-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "pipeline_from_disk = PipelineModel.load(path_model_with_pip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "introductory-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col, sum\n",
    "\n",
    "transformed_output = pipeline_from_disk.transform(data_in_stream)\\\n",
    "  .agg((sum(when(col('prediction') == 1, 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ethical-interstate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[sum(CASE WHEN (prediction = 1) THEN 1 END): bigint]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "threatened-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = transformed_output.writeStream.outputMode('complete').queryName(\"spark_streaming_ml\").format('memory').start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "collaborative-stable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No physical plan. Waiting for data.\n"
     ]
    }
   ],
   "source": [
    "query.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cosmetic-player",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.awaitTermination(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "union-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import sql\n",
    "\n",
    "output = spark.sql(\"select * from spark_streaming_ml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "recorded-tours",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+\n",
      "|sum(CASE WHEN (prediction = 1) THEN 1 END)|\n",
      "+------------------------------------------+\n",
      "|                                        10|\n",
      "+------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-addition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
