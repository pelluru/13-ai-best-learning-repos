{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mobile-switzerland",
   "metadata": {},
   "source": [
    "# Zoo Animal Clasification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-virus",
   "metadata": {},
   "source": [
    "\n",
    "Use Machine Learning Methods to Correctly Classify Animals Based Upon Attributes.\n",
    "Dataset by Kaggle. More information can be found [here](https://www.kaggle.com/uciml/zoo-animal-classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "qualified-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create a spark session\n",
    "\n",
    "from pyspark.sql import SparkSession \n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"Intro\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-korea",
   "metadata": {},
   "source": [
    "# Provide custome schema for the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "orange-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.types import StructField, StructType, StringType, DoubleType\n",
    "# notice that although the most of the columns are of integet type, the custome schema will use integer type.\n",
    "# This is because this is the statistic functionality expected numeric type. \n",
    "\n",
    "custom_schema = StructType([\n",
    "    StructField(\"animal_name\", StringType(), True),\n",
    "    StructField(\"hair\", DoubleType(), True),\n",
    "    StructField(\"feathers\", DoubleType(), True),\n",
    "    StructField(\"eggs\", DoubleType(), True),\n",
    "    StructField(\"milk\", DoubleType(), True),\n",
    "    StructField(\"airborne\", DoubleType(), True),\n",
    "    StructField(\"aquatic\", DoubleType(), True),\n",
    "    StructField(\"predator\", DoubleType(), True),\n",
    "    StructField(\"toothed\", DoubleType(), True),\n",
    "    StructField(\"backbone\", DoubleType(), True),\n",
    "    StructField(\"breathes\", DoubleType(), True),\n",
    "    StructField(\"venomous\", DoubleType(), True),\n",
    "    StructField(\"fins\", DoubleType(), True),\n",
    "    StructField(\"legs\", DoubleType(), True),\n",
    "    StructField(\"tail\", DoubleType(), True),\n",
    "    StructField(\"domestic\", DoubleType(), True),\n",
    "    StructField(\"catsize\", DoubleType(), True),\n",
    "    StructField(\"class_type\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "advisory-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "zoo_data = spark.read.format(\"csv\")\\\n",
    "    .schema(custom_schema) \\\n",
    "    .option(\"header\", True) \\\n",
    "    .load(\"../datasets/zoo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "varied-element",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(animal_name='aardvark', hair=1.0, feathers=0.0, eggs=0.0, milk=1.0, airborne=0.0, aquatic=0.0, predator=1.0, toothed=1.0, backbone=1.0, breathes=1.0, venomous=0.0, fins=0.0, legs=4.0, tail=0.0, domestic=0.0, catsize=1.0, class_type='1')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zoo_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "under-clinic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- animal_name: string (nullable = true)\n",
      " |-- hair: double (nullable = true)\n",
      " |-- feathers: double (nullable = true)\n",
      " |-- eggs: double (nullable = true)\n",
      " |-- milk: double (nullable = true)\n",
      " |-- airborne: double (nullable = true)\n",
      " |-- aquatic: double (nullable = true)\n",
      " |-- predator: double (nullable = true)\n",
      " |-- toothed: double (nullable = true)\n",
      " |-- backbone: double (nullable = true)\n",
      " |-- breathes: double (nullable = true)\n",
      " |-- venomous: double (nullable = true)\n",
      " |-- fins: double (nullable = true)\n",
      " |-- legs: double (nullable = true)\n",
      " |-- tail: double (nullable = true)\n",
      " |-- domestic: double (nullable = true)\n",
      " |-- catsize: double (nullable = true)\n",
      " |-- class_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zoo_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-closure",
   "metadata": {},
   "source": [
    "# Calculate statistics\n",
    "for this, we will use the Summarizer functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "unexpected-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistic functionaly can only work on vector.\n",
    "# Hence we will drop the columns of type string we dont need at the moment.\n",
    "\n",
    "zoo_data_for_statistics = zoo_data.drop('animal_name','lass_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-tulsa",
   "metadata": {},
   "source": [
    "## Turn the columns into a vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-carrier",
   "metadata": {},
   "source": [
    "Notice that for simplifying the example, we are going to examin the following columns:\n",
    "\n",
    "* feathers\n",
    "* milk\n",
    "* fins\n",
    "* domestic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "expanded-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# use vector transformer as describe in the book under transofrmers in chapter 3\n",
    "vecAssembler = VectorAssembler(outputCol=\"features\")\n",
    "# assemble only part of the columns for the example\n",
    "vecAssembler.setInputCols([\"feathers\",\"milk\",\"fins\",\"domestic\"])\n",
    "\n",
    "vector_df = vecAssembler.transform(zoo_data_for_statistics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "criminal-reliance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hair: double (nullable = true)\n",
      " |-- feathers: double (nullable = true)\n",
      " |-- eggs: double (nullable = true)\n",
      " |-- milk: double (nullable = true)\n",
      " |-- airborne: double (nullable = true)\n",
      " |-- aquatic: double (nullable = true)\n",
      " |-- predator: double (nullable = true)\n",
      " |-- toothed: double (nullable = true)\n",
      " |-- backbone: double (nullable = true)\n",
      " |-- breathes: double (nullable = true)\n",
      " |-- venomous: double (nullable = true)\n",
      " |-- fins: double (nullable = true)\n",
      " |-- legs: double (nullable = true)\n",
      " |-- tail: double (nullable = true)\n",
      " |-- domestic: double (nullable = true)\n",
      " |-- catsize: double (nullable = true)\n",
      " |-- class_type: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "warming-proceeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|aggregate_metrics(features, 1.0)                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|{[0.19801980198019803,0.40594059405940597,0.16831683168316833,0.12871287128712872], [0.1603960396039604,0.24356435643564356,0.1413861386138614,0.11326732673267326], [20.0,41.0,17.0,13.0], [4.47213595499958,6.4031242374328485,4.123105625617661,3.605551275463989], [0.4004947435409863,0.4935223970962651,0.37601348195757744,0.33655211592363116], [20.0,41.0,17.0,13.0], [20.0,41.0,17.0,13.0], [1.0,1.0,1.0,1.0], [0.0,0.0,0.0,0.0]}|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.stat import Summarizer\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "# create summarizer for multiple metrics \"mean\",\"variance\",\"normL1\",\"normL2\",\"std\" and \"sum\".\n",
    "summarizer = Summarizer.metrics(\"mean\",\"variance\",\"normL1\",\"normL2\",\"std\",\"sum\",\"numNonZeros\",\"max\",\"min\")\n",
    "\n",
    "\n",
    "# compute statistics for multiple metrics with weight\n",
    "statistics_df = vector_df.select(summarizer.summary(vector_df.features))\n",
    "\n",
    "statistics_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-listing",
   "metadata": {},
   "source": [
    "Notice that statistics dataframe has only one column named aggregate_metrics, where aggregate_metrics coluumns has more columns, where each one of them is a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "invalid-corner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- aggregate_metrics(features, 1.0): struct (nullable = false)\n",
      " |    |-- mean: vector (nullable = false)\n",
      " |    |-- variance: vector (nullable = false)\n",
      " |    |-- normL1: vector (nullable = false)\n",
      " |    |-- normL2: vector (nullable = false)\n",
      " |    |-- std: vector (nullable = false)\n",
      " |    |-- sum: vector (nullable = false)\n",
      " |    |-- numNonZeros: vector (nullable = false)\n",
      " |    |-- max: vector (nullable = false)\n",
      " |    |-- min: vector (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "statistics_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-investment",
   "metadata": {},
   "source": [
    "For enabling easier access to the data, we use explode functionality that flattens one hirarchy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "motivated-basement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------+\n",
      "|std(features)                                                                  |\n",
      "+-------------------------------------------------------------------------------+\n",
      "|[0.4004947435409863,0.4935223970962651,0.37601348195757744,0.33655211592363116]|\n",
      "+-------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute statistics for single metric \"std\" without the rest\n",
    "vector_df.select(Summarizer.std(vector_df.features)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-insulin",
   "metadata": {},
   "source": [
    "From [wikipedia](https://en.wikipedia.org/wiki/Standard_deviation) std - Standard deviation is a measure of the amount of variation or dispersion of a set of values. A low standard deviation indicates that the values tend to be close to the mean (also called the expected value) of the set, while a high standard deviation indicates that the values are spread out over a wider range. \n",
    "\n",
    "Looking at the vector results, the distance from the among each individual feature is lower than 0.5\n",
    "Our features: \"feathers\",\"milk\",\"fins\",\"domestic\"\n",
    "\n",
    "The reson for it, mainly is, the data should be represented in boolean since each feature is a yes/no fearure.\n",
    "Feathers =1 , means that this animal has feathers and so on.\n",
    "\n",
    "Now that we know this, let's take a look at count, which will tell us how many animals in the database has feathers, milk, fins or domestic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "continued-wholesale",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|sum(features)        |\n",
      "+---------------------+\n",
      "|[20.0,41.0,17.0,13.0]|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute statistics for single metric \"sum\" without the rest\n",
    "vector_df.select(Summarizer.sum(vector_df.features)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-philadelphia",
   "metadata": {},
   "source": [
    "`sum` provides us with a more relatable information that we can use to understand the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "varying-purse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------+\n",
      "|variance(features)                                                             |\n",
      "+-------------------------------------------------------------------------------+\n",
      "|[0.1603960396039604,0.24356435643564356,0.1413861386138614,0.11326732673267326]|\n",
      "+-------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute statistics for single metric \"variance\" without the rest\n",
    "vector_df.select(Summarizer.variance(vector_df.features)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "spanish-fellow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|count(features)|\n",
      "+---------------+\n",
      "|101            |\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute statistics for single metric \"count\" without the rest\n",
    "vector_df.select(Summarizer.count(vector_df.features)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "happy-insider",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|numNonZeros(features)|\n",
      "+---------------------+\n",
      "|[20.0,41.0,17.0,13.0]|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute statistics for single metric \"numNonZeros\" without the rest\n",
    "vector_df.select(Summarizer.numNonZeros(vector_df.features)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "progressive-thread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|max(features)    |\n",
      "+-----------------+\n",
      "|[1.0,1.0,1.0,1.0]|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute statistics for single metric \"max\" without the rest\n",
    "vector_df.select(Summarizer.max(vector_df.features)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "atlantic-empty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|normL1(features)     |\n",
      "+---------------------+\n",
      "|[20.0,41.0,17.0,13.0]|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute statistics for single metric \"normL1\" without the rest\n",
    "vector_df.select(Summarizer.normL1(vector_df.features)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "steady-midwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------+\n",
      "|normL2(features)                                                         |\n",
      "+-------------------------------------------------------------------------+\n",
      "|[4.47213595499958,6.4031242374328485,4.123105625617661,3.605551275463989]|\n",
      "+-------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute statistics for single metric \"normL2\" without the rest\n",
    "vector_df.select(Summarizer.normL2(vector_df.features)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-hormone",
   "metadata": {},
   "source": [
    "# Testing features correlations\n",
    "As part of understanding each featres statistics on its own, let's understand the correlation between the features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-living",
   "metadata": {},
   "source": [
    "### Notice\n",
    "This functionality also requires a vector, we will use the one from the earlier computation - `vector_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "authentic-paradise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation matrix:\n",
      "DenseMatrix([[ 1.        , -0.41076061, -0.22354106,  0.03158624],\n",
      "             [-0.41076061,  1.        , -0.15632771,  0.16392762],\n",
      "             [-0.22354106, -0.15632771,  1.        , -0.09388671],\n",
      "             [ 0.03158624,  0.16392762, -0.09388671,  1.        ]])\n",
      "\n",
      "Spearman correlation matrix:\n",
      "DenseMatrix([[ 1.        , -0.41076061, -0.22354106,  0.03158624],\n",
      "             [-0.41076061,  1.        , -0.15632771,  0.16392762],\n",
      "             [-0.22354106, -0.15632771,  1.        , -0.09388671],\n",
      "             [ 0.03158624,  0.16392762, -0.09388671,  1.        ]])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.stat import KolmogorovSmirnovTest\n",
    "\n",
    "r1 = Correlation.corr(vector_df, \"features\").head()\n",
    "print(\"Pearson correlation matrix:\\n\" + str(r1[0])+ \"\\n\")\n",
    "\n",
    "r2 = Correlation.corr(vector_df, \"features\", \"spearman\").head()\n",
    "print(\"Spearman correlation matrix:\\n\" + str(r2[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-coaching",
   "metadata": {},
   "source": [
    "Breakdown of the correlation metrix is in the book, chapter 3 under statistics. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "psychological-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.stat import KolmogorovSmirnovTest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-toronto",
   "metadata": {},
   "source": [
    "## ChiSquareTest\n",
    "\n",
    "Testing the p-value of the columns:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-administration",
   "metadata": {},
   "source": [
    "This requeires vector as well Hence we will use the prcompute vector from before. \n",
    "\n",
    "Notice that label in this case, has to be of type numberic.\n",
    "To tranform the label into numberic, we will use the StringIndexer transofmer functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "descending-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"class_type\", outputCol=\"label\")\n",
    "indexed_lable = indexer.fit(vector_df).transform(vector_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "double-taiwan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hair: double (nullable = true)\n",
      " |-- feathers: double (nullable = true)\n",
      " |-- eggs: double (nullable = true)\n",
      " |-- milk: double (nullable = true)\n",
      " |-- airborne: double (nullable = true)\n",
      " |-- aquatic: double (nullable = true)\n",
      " |-- predator: double (nullable = true)\n",
      " |-- toothed: double (nullable = true)\n",
      " |-- backbone: double (nullable = true)\n",
      " |-- breathes: double (nullable = true)\n",
      " |-- venomous: double (nullable = true)\n",
      " |-- fins: double (nullable = true)\n",
      " |-- legs: double (nullable = true)\n",
      " |-- tail: double (nullable = true)\n",
      " |-- domestic: double (nullable = true)\n",
      " |-- catsize: double (nullable = true)\n",
      " |-- class_type: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexed_lable.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "completed-daily",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=SparseVector(4, {1: 1.0}))]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_lable.select(\"features\").take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "noticed-burke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[hair: double, feathers: double, eggs: double, milk: double, airborne: double, aquatic: double, predator: double, toothed: double, backbone: double, breathes: double, venomous: double, fins: double, legs: double, tail: double, domestic: double, catsize: double, class_type: string, features: vector, label: double]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "european-hospital",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(degreesOfFreedom=[6, 6, 6, 6])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml.stat import ChiSquareTest\n",
    "\n",
    "chiSqResult = ChiSquareTest.test(indexed_lable, 'features', 'label')\n",
    "chiSqResult.select(\"degreesOfFreedom\").collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "located-convert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.99999999999999"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chiSqResult = ChiSquareTest.test(indexed_lable, 'features', 'label', True)\n",
    "row = chiSqResult.orderBy(\"featureIndex\").collect()\n",
    "row[0].statistic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "popular-extension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(featureIndex=0, pValue=0.0, degreesOfFreedom=6, statistic=100.99999999999999),\n",
       " Row(featureIndex=1, pValue=0.0, degreesOfFreedom=6, statistic=101.0),\n",
       " Row(featureIndex=2, pValue=3.4638958368304884e-14, degreesOfFreedom=6, statistic=75.21350003415999),\n",
       " Row(featureIndex=3, pValue=0.5681588672220808, degreesOfFreedom=6, statistic=4.8118701947677085)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-parallel",
   "metadata": {},
   "source": [
    "Reminder that for simplifying the example, we used the following columns:\n",
    "* feathers\n",
    "* milk\n",
    "* fins\n",
    "* domestic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-bulletin",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
