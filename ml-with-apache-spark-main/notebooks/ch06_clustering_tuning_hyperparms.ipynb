{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "processed-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"Intro\") \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "special-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, DoubleType\n",
    "\n",
    "custom_schema = StructType([\n",
    "    StructField(\"Make\", StringType(), True),\n",
    "    StructField(\"Model\", StringType(), True),\n",
    "    StructField(\"Vehicle Class\", StringType(), True),\n",
    "    StructField(\"Cylinders\", DoubleType(), True),\n",
    "    StructField(\"Transmission\", StringType(), True),\n",
    "    StructField(\"Fuel Type\", StringType(), True),\n",
    "    StructField(\"Fuel Consumption City (L/100 km)\", DoubleType(), True),\n",
    "    StructField(\"Fuel Consumption Hwy (L/100 km)\", DoubleType(), True),\n",
    "    StructField(\"Fuel Consumption Comb (L/100 km)\", DoubleType(), True),\n",
    "    StructField(\"Fuel Consumption Comb (mpg)\", DoubleType(), True),\n",
    "    StructField(\"CO2\", DoubleType(), True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "green-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "co2_data = spark.read.format(\"csv\")\\\n",
    "    .schema(custom_schema) \\\n",
    "    .option(\"header\", True) \\\n",
    "    .load(\"CO2_Emissions_Canada.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "raised-equality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Make='ACURA', Model='ILX', Vehicle Class='COMPACT', Cylinders=2.0, Transmission='4', Fuel Type='AS5', Fuel Consumption City (L/100 km)=None, Fuel Consumption Hwy (L/100 km)=9.9, Fuel Consumption Comb (L/100 km)=6.7, Fuel Consumption Comb (mpg)=8.5, CO2=33.0),\n",
       " Row(Make='ACURA', Model='ILX', Vehicle Class='COMPACT', Cylinders=2.4, Transmission='4', Fuel Type='M6', Fuel Consumption City (L/100 km)=None, Fuel Consumption Hwy (L/100 km)=11.2, Fuel Consumption Comb (L/100 km)=7.7, Fuel Consumption Comb (mpg)=9.6, CO2=29.0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co2_data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "intermediate-israeli",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_only_continues_values = {'Fuel Consumption City (L/100 km)':0}\n",
    "#                               \"Fuel Consumption Hwy (L/100 km)\",\n",
    "#         \"Fuel Consumption Comb (L/100 km)\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cultural-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_data = co2_data.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mature-checkout",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- Vehicle Class: string (nullable = true)\n",
      " |-- Cylinders: double (nullable = false)\n",
      " |-- Transmission: string (nullable = true)\n",
      " |-- Fuel Type: string (nullable = true)\n",
      " |-- Fuel Consumption City (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Hwy (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (mpg): double (nullable = false)\n",
      " |-- CO2: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "co2_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "level-mixture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Make='ACURA', Model='ILX', Vehicle Class='COMPACT', Cylinders=2.0, Transmission='4', Fuel Type='AS5', Fuel Consumption City (L/100 km)=0.0, Fuel Consumption Hwy (L/100 km)=9.9, Fuel Consumption Comb (L/100 km)=6.7, Fuel Consumption Comb (mpg)=8.5, CO2=33.0),\n",
       " Row(Make='ACURA', Model='ILX', Vehicle Class='COMPACT', Cylinders=2.4, Transmission='4', Fuel Type='M6', Fuel Consumption City (L/100 km)=0.0, Fuel Consumption Hwy (L/100 km)=11.2, Fuel Consumption Comb (L/100 km)=7.7, Fuel Consumption Comb (mpg)=9.6, CO2=29.0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co2_data.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-sellers",
   "metadata": {},
   "source": [
    "# Prep the data for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-embassy",
   "metadata": {},
   "source": [
    "turn the feature columns into one indexed column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "expanded-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import FeatureHasher\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "cols = [\"Make\", \"Model\", \"Vehicle Class\",\"Cylinders\",\"Transmission\",\"Fuel Type\",\n",
    "        \"Fuel Consumption City (L/100 km)\", \"Fuel Consumption Hwy (L/100 km)\",\n",
    "        \"Fuel Consumption Comb (L/100 km)\",\"Fuel Consumption Comb (mpg)\"]\n",
    "\n",
    "cols_only_continues = [\"Fuel Consumption City (L/100 km)\", \"Fuel Consumption Hwy (L/100 km)\",\n",
    "        \"Fuel Consumption Comb (L/100 km)\"]\n",
    "\n",
    "hasher = FeatureHasher(outputCol=\"hashed_features\", inputCols=cols_only_continues)\n",
    "data = hasher.transform(co2_data)\n",
    "                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hairy-mountain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n",
      "|hashed_features                              |\n",
      "+---------------------------------------------+\n",
      "|(262144,[38607,109231,228390],[0.0,9.9,6.7]) |\n",
      "|(262144,[38607,109231,228390],[0.0,11.2,7.7])|\n",
      "|(262144,[38607,109231,228390],[0.0,6.0,5.8]) |\n",
      "|(262144,[38607,109231,228390],[0.0,12.7,9.1])|\n",
      "|(262144,[38607,109231,228390],[0.0,12.1,8.7])|\n",
      "+---------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(\"hashed_features\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "closed-boulder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(hashed_features=SparseVector(262144, {38607: 0.0, 109231: 9.9, 228390: 6.7}))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select(\"hashed_features\").take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vulnerable-right",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n",
      "|hashed_features                              |\n",
      "+---------------------------------------------+\n",
      "|(262144,[38607,109231,228390],[0.0,9.9,6.7]) |\n",
      "|(262144,[38607,109231,228390],[0.0,11.2,7.7])|\n",
      "|(262144,[38607,109231,228390],[0.0,6.0,5.8]) |\n",
      "|(262144,[38607,109231,228390],[0.0,12.7,9.1])|\n",
      "|(262144,[38607,109231,228390],[0.0,12.1,8.7])|\n",
      "+---------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(\"hashed_features\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "stupid-modeling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- Vehicle Class: string (nullable = true)\n",
      " |-- Cylinders: double (nullable = false)\n",
      " |-- Transmission: string (nullable = true)\n",
      " |-- Fuel Type: string (nullable = true)\n",
      " |-- Fuel Consumption City (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Hwy (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (mpg): double (nullable = false)\n",
      " |-- CO2: double (nullable = false)\n",
      " |-- hashed_features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-roots",
   "metadata": {},
   "source": [
    "# time for selecting the most meaninful features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "breeding-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import UnivariateFeatureSelector\n",
    "\n",
    "selector = UnivariateFeatureSelector(outputCol=\"selectedFeatures\", featuresCol=\"hashed_features\", labelCol=\"CO2\")\n",
    "\n",
    "selector.setFeatureType(\"continuous\")\n",
    "selector.setLabelType(\"continuous\")\n",
    "\n",
    "model = selector.fit(data)\n",
    "data = model.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-moscow",
   "metadata": {},
   "source": [
    " ## Tryout LDA clustring algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "actual-newfoundland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from pyspark.ml.clustering import LDA\n",
    "\n",
    "\n",
    "lda = LDA(k=2, seed=1, optimizer=\"em\",featuresCol=\"selectedFeatures\")\n",
    "lda.setMaxIter(100)\n",
    "\n",
    "\n",
    "lda.clear(lda.maxIter)\n",
    "lda_model = lda.fit(data)\n",
    "lda_model.setSeed(1)\n",
    "\n",
    "# check if the model itself is distributed across Spark executres\n",
    "lda_model.isDistributed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "pretty-appearance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+--------------------+\n",
      "|topic|termIndices|         termWeights|\n",
      "+-----+-----------+--------------------+\n",
      "|    0|   [48, 49]|[0.58104675033297...|\n",
      "|    1|   [48, 49]|[0.58168999987474...|\n",
      "+-----+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_model.describeTopics().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "configured-triple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.vocabSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "embedded-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_predictions = lda_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "respected-southwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- Vehicle Class: string (nullable = true)\n",
      " |-- Cylinders: double (nullable = false)\n",
      " |-- Transmission: string (nullable = true)\n",
      " |-- Fuel Type: string (nullable = true)\n",
      " |-- Fuel Consumption City (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Hwy (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (mpg): double (nullable = false)\n",
      " |-- CO2: double (nullable = false)\n",
      " |-- hashed_features: vector (nullable = true)\n",
      " |-- selectedFeatures: vector (nullable = true)\n",
      " |-- topicDistribution: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "exotic-endorsement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+\n",
      "|topicDistribution                      |\n",
      "+---------------------------------------+\n",
      "|[0.5000015176580933,0.4999984823419068]|\n",
      "|[0.4999995563245016,0.5000004436754983]|\n",
      "+---------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_predictions.select(\"topicDistribution\").show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-brake",
   "metadata": {},
   "source": [
    "# Tryout KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "creative-affiliation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'euclidean'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "\n",
    "\n",
    "kmeans = KMeans(k=3)\n",
    "kmeans.setSeed(10)\n",
    "kmeans.setFeaturesCol(\"selectedFeatures\")\n",
    "\n",
    "kmeans_model = kmeans.fit(data)\n",
    "kmeans_model.getDistanceMeasure()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "gothic-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_predictions = kmeans_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "wired-remark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         2|\n",
      "|         2|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmeans_predictions.select(\"prediction\").show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "proprietary-devices",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|         1|\n",
      "|         2|\n",
      "|         0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmeans_predictions.select(\"prediction\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "durable-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = kmeans_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "technological-stability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- prediction: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary.cluster.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-spain",
   "metadata": {},
   "source": [
    "# Tryout GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dimensional-wisdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import GaussianMixture\n",
    "\n",
    "gm = GaussianMixture(k=42, tol=0.01, seed=10, featuresCol=\"selectedFeatures\", maxIter=100)\n",
    "gm_model = gm.fit(data)\n",
    "\n",
    "gm_predictions = gm_model.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-wonder",
   "metadata": {},
   "source": [
    "Print the model params using `explainParams()` functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "electric-chaos",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('aggregationDepth: suggested depth for treeAggregate (>= 2). (default: 2)\\n'\n",
      " 'featuresCol: features column name. (default: features, current: '\n",
      " 'selectedFeatures)\\n'\n",
      " 'k: Number of independent Gaussians in the mixture model. Must be > 1. '\n",
      " '(default: 2, current: 42)\\n'\n",
      " 'maxIter: max number of iterations (>= 0). (default: 100, current: 100)\\n'\n",
      " 'predictionCol: prediction column name. (default: prediction)\\n'\n",
      " 'probabilityCol: Column name for predicted class conditional probabilities. '\n",
      " 'Note: Not all models output well-calibrated probability estimates! These '\n",
      " 'probabilities should be treated as confidences, not precise probabilities. '\n",
      " '(default: probability)\\n'\n",
      " 'seed: random seed. (default: 4621526457424974748, current: 10)\\n'\n",
      " 'tol: the convergence tolerance for iterative algorithms (>= 0). (default: '\n",
      " '0.01, current: 0.01)\\n'\n",
      " 'weightCol: weight column name. If this is not set or empty, we treat all '\n",
      " 'instance weights as 1.0. (undefined)')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "params = gm_model.explainParams()\n",
    "pp.pprint(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-depth",
   "metadata": {},
   "source": [
    "# Constructing - The Pipeline API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "blessed-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[hasher,selector, gm])\n",
    "# Fit the pipeline to training data.\n",
    "pipeline_model = pipeline.fit(co2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adult-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_by_pipeline = pipeline_model.transform(co2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "necessary-violation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- Vehicle Class: string (nullable = true)\n",
      " |-- Cylinders: double (nullable = false)\n",
      " |-- Transmission: string (nullable = true)\n",
      " |-- Fuel Type: string (nullable = true)\n",
      " |-- Fuel Consumption City (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Hwy (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (mpg): double (nullable = false)\n",
      " |-- CO2: double (nullable = false)\n",
      " |-- hashed_features: vector (nullable = true)\n",
      " |-- selectedFeatures: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_by_pipeline.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-serum",
   "metadata": {},
   "source": [
    "## Evaluating clustring models\n",
    "\n",
    "Notice we are not using this evaluator for LDA since it outputs topicDistribution and not one numeric prdiction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "european-grant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans: 0.6791002214675337\n",
      "GM: -0.1517797715036008\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "evaluator = ClusteringEvaluator(featuresCol='selectedFeatures')\n",
    "evaluator.setPredictionCol(\"prediction\")\n",
    "\n",
    "#evaluate with eucliden distance\n",
    "print(\"kmeans: \"+str(evaluator.evaluate(kmeans_predictions)))\n",
    "print(\"GM: \"+ str(evaluator.evaluate(gm_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "expressed-exposure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.isLargerBetter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "silver-instrument",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans: -0.07958234502129219\n",
      "GM: -0.19012403274289733\n"
     ]
    }
   ],
   "source": [
    "evaluator.setDistanceMeasure(\"cosine\")\n",
    "print(\"kmeans: \"+str(evaluator.evaluate(kmeans_predictions)))\n",
    "print(\"GM: \"+ str(evaluator.evaluate(gm_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "novel-brother",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.isLargerBetter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "mysterious-press",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"distanceMeasure: The distance measure. Supported options: 'squaredEuclidean' and 'cosine'. (default: squaredEuclidean, current: cosine)\\nfeaturesCol: features column name. (default: features, current: selectedFeatures)\\nmetricName: metric name in evaluation (silhouette) (default: silhouette)\\npredictionCol: prediction column name. (default: prediction, current: prediction)\\nweightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.explainParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-saudi",
   "metadata": {},
   "source": [
    "### Since evaluator output for `isLargerBetter` was true, we can define that kmeans algorithm produced a better model than GM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-genome",
   "metadata": {},
   "source": [
    "# Hyperparameters and Tuning experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "documented-stranger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit , ParamGridBuilder\n",
    "\n",
    "grid = ParamGridBuilder().addGrid(kmeans.maxIter, [20,50,100]).build()\n",
    "\n",
    "tvs = TrainValidationSplit(estimator=kmeans, estimatorParamMaps=grid, evaluator=evaluator,\n",
    "                           collectSubModels=True, parallelism=1, seed=42)\n",
    "tvs_model = tvs.fit(data)\n",
    "tvs_model.getTrainRatio()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "skilled-opposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.06270405194965402, -0.06402059325959049, -0.06402059325959049]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvs_model.validationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "interesting-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit , ParamGridBuilder\n",
    "\n",
    "grid = ParamGridBuilder().addGrid(kmeans.maxIter, [20,50,100]) \\\n",
    "        .addGrid(kmeans.distanceMeasure, ['euclidean','cosine']).build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "transsexual-georgia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.06270405194965402, -0.06402059325959049, -0.06402059325959049]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvs_model.validationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "tested-sleeping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.06292946960479909,\n",
       " -0.06292946960479909,\n",
       " 0.5520132682136769,\n",
       " 0.5520132682136769,\n",
       " -0.06292946960479909,\n",
       " -0.06292946960479909,\n",
       " 0.5520132682136769,\n",
       " 0.5520132682136769,\n",
       " -0.06292946960479909,\n",
       " -0.06292946960479909,\n",
       " 0.5520132682136769,\n",
       " 0.5520132682136769]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit , ParamGridBuilder\n",
    "\n",
    "grid = ParamGridBuilder().addGrid(kmeans.maxIter, [20,50,100]) \\\n",
    "        .addGrid(kmeans.distanceMeasure, ['euclidean','cosine']) \\\n",
    "        .addGrid(evaluator.distanceMeasure, ['euclidean','cosine']).build()\n",
    "\n",
    "\n",
    "tvs = TrainValidationSplit(estimator=kmeans, estimatorParamMaps=grid, evaluator=evaluator,\n",
    "                           collectSubModels=True, parallelism=1, seed=42, trainRatio=0.8)\n",
    "tvs_model = tvs.fit(data)\n",
    "tvs_model.validationMetrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-fisher",
   "metadata": {},
   "source": [
    "## Adding evaluator to the grid params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "individual-government",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.06292946960479909,\n",
       " -0.06292946960479909,\n",
       " 0.5520132682136769,\n",
       " 0.5520132682136769,\n",
       " -0.06292946960479909,\n",
       " -0.06292946960479909,\n",
       " 0.5520132682136769,\n",
       " 0.5520132682136769,\n",
       " -0.06292946960479909,\n",
       " -0.06292946960479909,\n",
       " 0.5520132682136769,\n",
       " 0.5520132682136769]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit , ParamGridBuilder\n",
    "\n",
    "\n",
    "grid = ParamGridBuilder().addGrid(kmeans.maxIter, [20,50,100]) \\\n",
    "        .addGrid(kmeans.distanceMeasure, ['euclidean','cosine']) \\\n",
    "        .addGrid(evaluator.distanceMeasure, ['euclidean','cosine'])\\\n",
    "        .baseOn({kmeans.featuresCol: 'selectedFeatures'}) \\\n",
    "        .build()\n",
    "\n",
    "tvs = TrainValidationSplit(estimator=kmeans, estimatorParamMaps=grid, evaluator=evaluator,\n",
    "                           collectSubModels=True, parallelism=1, seed=42, trainRatio=0.8)\n",
    "tvs_model = tvs.fit(data)\n",
    "tvs_model.validationMetrics\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "swedish-annex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvs_model.subModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "amended-personality",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_models = tvs_model.subModels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-harris",
   "metadata": {},
   "source": [
    "# Advanced Split\n",
    "\n",
    "the subModels are printed here as an example, do not use for real systems!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "worthy-arrest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50],\n",
       " [KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50],\n",
       " [KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_03239630e943, k=3, distanceMeasure=cosine, numFeatures=50]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, CrossValidatorModel\n",
    "\n",
    "\n",
    "cv = CrossValidator(estimator=kmeans, estimatorParamMaps=grid, evaluator=evaluator,\n",
    "                           collectSubModels=True,  parallelism=2, numFolds=3)\n",
    "\n",
    "cv_model = cv.fit(data)\n",
    "cv_model.subModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "defensive-cardiff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv_model.subModels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "novel-relay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv_model.subModels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aboriginal-scale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.07863039137980392,\n",
       " -0.07863039137980392,\n",
       " 0.5623024101653663,\n",
       " 0.5623024101653663,\n",
       " -0.0793314856527143,\n",
       " -0.0793314856527143,\n",
       " 0.5623024101653663,\n",
       " 0.5623024101653663,\n",
       " -0.0793314856527143,\n",
       " -0.0793314856527143,\n",
       " 0.5623024101653663,\n",
       " 0.5623024101653663]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.avgMetrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
