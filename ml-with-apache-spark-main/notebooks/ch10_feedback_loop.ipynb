{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94073cfd",
   "metadata": {},
   "source": [
    "# Chapter 10 - the feedback loop\n",
    "\n",
    "As you learned in chapter 10 about the feedback loop, let's look at an example that shows how it works.\n",
    "\n",
    "Our system uses Apache Spark for batch and stream processing. Our machine learning model was built with Spark.\n",
    "Spark is serving the machine learning model as part of the work with stractured streaming.\n",
    "\n",
    "For the example. we will generate some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af8fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# machine learning model pipeline\n",
    "\n",
    "# stream data spark\n",
    "\n",
    "# table with actual and prediction\n",
    "\n",
    "# fake alert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77ef4224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"machine_learning_streaming\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c055bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_stream = spark.readStream.format(\"csv\").option(\"header\",True)\\\n",
    "    .schema(schema).option(\"ignoreLeadingWhiteSpace\",True)\\\n",
    "    .option(\"mode\",\"dropMalformed\").option(\"maxFilesPerTrigger\",1)\\\n",
    "    .load({data_path}).withColumnRenamed(\"output\",\"label\")\n",
    "\n",
    "\n",
    "some_model = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15db339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_predict = some_model.transform(source_stream).select('probability','prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff84a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_actual = other_source_stream_with_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f747b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply watermarks on event-time columns\n",
    "stream_predict_watermarks = stream_predict.withWatermark(\"impressionTime\", \"2 hours\")\n",
    "stream_actual_watermark = stream_actual.withWatermark(\"actualTime\", \"3 hours\")\n",
    "\n",
    "\n",
    "some_model.join(stream_predict,\n",
    "               expr(\"\"\" predictId = actualId AND\n",
    "    actualTime >= impressionTime AND\n",
    "    actualTime <= impressionTime + interval 1 hour\n",
    "    \"\"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
